{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T02:34:48.510588Z",
     "iopub.status.busy": "2025-09-05T02:34:48.510299Z",
     "iopub.status.idle": "2025-09-05T02:34:48.516678Z",
     "shell.execute_reply": "2025-09-05T02:34:48.515226Z",
     "shell.execute_reply.started": "2025-09-05T02:34:48.510568Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-05T03:13:06.227105Z",
     "start_time": "2025-09-05T03:13:06.209546Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "tqdm.pandas()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"font-family: 'Garamond', serif; font-size: 22px; color: #ffffff; background-color: #34568B; text-align: center; padding: 15px; border-radius: 10px; border: 2px solid #FF6F61; box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">Step 1: Load the data</div>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Dataset Metadata</div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Overview\n",
    "\n",
    "The data has been split into two groups:\n",
    "\n",
    "- **Training set** (`train.csv`)\n",
    "- **Test set** (`test.csv`)\n",
    "\n",
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the **“ground truth”**) for each passenger. Your model will be based on **features** like passengers’ gender and class. You can also use **feature engineering** to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on **unseen data**. For the test set, we do not provide the ground truth for each passenger. It is your job to **predict these outcomes**. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include `gender_submission.csv`, a set of predictions that assume **all and only female passengers survive**, as an example of what a submission file should look like.\n",
    "\n",
    "---\n",
    "\n",
    "# Data Dictionary\n",
    "\n",
    "| Variable   | Definition                             | Key                                           |\n",
    "|------------|----------------------------------------|-----------------------------------------------|\n",
    "| survival   | Survival                               | 0 = No, 1 = Yes                               |\n",
    "| pclass     | Ticket class                           | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| sex        | Sex                                    |                                               |\n",
    "| age        | Age in years                           |                                               |\n",
    "| sibsp      | # of siblings / spouses aboard Titanic |                                               |\n",
    "| parch      | # of parents / children aboard Titanic |                                               |\n",
    "| ticket     | Ticket number                          |                                               |\n",
    "| fare       | Passenger fare                         |                                               |\n",
    "| cabin      | Cabin number                           |                                               |\n",
    "| embarked   | Port of Embarkation                    | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "---\n",
    "\n",
    "# Variable Notes\n",
    "\n",
    "- **pclass**: A proxy for socio-economic status (SES)\n",
    "  - 1st = Upper\n",
    "  - 2nd = Middle\n",
    "  - 3rd = Lower\n",
    "\n",
    "- **age**: Age is fractional if less than 1. If the age is estimated, it is in the form of `xx.5`\n",
    "\n",
    "- **sibsp**: The dataset defines family relations in this way:\n",
    "  - **Sibling** = brother, sister, stepbrother, stepsister\n",
    "  - **Spouse** = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "- **parch**: The dataset defines family relations in this way:\n",
    "  - **Parent** = mother, father\n",
    "  - **Child** = daughter, son, stepdaughter, stepson\n",
    "  - Some children travelled only with a nanny, therefore `parch = 0` for them."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Load the data and display head</div>"
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T02:34:48.518748Z",
     "iopub.status.busy": "2025-09-05T02:34:48.518389Z",
     "iopub.status.idle": "2025-09-05T02:34:48.565466Z",
     "shell.execute_reply": "2025-09-05T02:34:48.564317Z",
     "shell.execute_reply.started": "2025-09-05T02:34:48.518720Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2025-09-05T02:56:38.121137Z",
     "start_time": "2025-09-05T02:56:38.091320Z"
    }
   },
   "source": [
    "# Check environment if in Kaggle\n",
    "extract_folder_path = '/kaggle/input/titanic' if os.path.exists('/kaggle/input/titanic') else './data'\n",
    "\n",
    "# Load the training data\n",
    "train_file_path = os.path.join(extract_folder_path, 'train.csv')\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "\n",
    "# Displaying the first few rows of the dataset\n",
    "train_data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">See the statistical summary of the dataset</div>"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T02:59:17.028969Z",
     "start_time": "2025-09-05T02:59:16.977738Z"
    }
   },
   "cell_type": "code",
   "source": "train_data.describe()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T02:59:37.347354Z",
     "start_time": "2025-09-05T02:59:37.316706Z"
    }
   },
   "cell_type": "code",
   "source": "train_data.info()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We find out that some columns are 'object' type, which means they are categorical variables. We will need to convert them into numerical format before feeding them into the model."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <div style=\"font-family: 'Garamond', serif; font-size: 22px; color: #ffffff; background-color: #34568B; text-align: center; padding: 15px; border-radius: 10px; border: 2px solid #FF6F61; box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">Step 2: Preprocess the data</div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Separating features and target variable</div>"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Separating the features and the target variable\n",
    "X = train_data.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "y = train_data['Survived']"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Preprocessing the data</div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For preprocessing, we will handle missing values and encode categorical variables. We will use `SimpleImputer` to fill in missing values and `OneHotEncoder` to convert categorical variables into a format that can be provided to ML algorithms to do a better job in prediction."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:06:50.064415Z",
     "start_time": "2025-09-05T03:06:50.039956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identifying numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Check the preprocessing results\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "X_preprocessed[0:5]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    , 22.    ,  1.    ,  0.    ,  7.25  ,  0.    ,  1.    ,\n",
       "         0.    ,  0.    ,  1.    ],\n",
       "       [ 1.    , 38.    ,  1.    ,  0.    , 71.2833,  1.    ,  0.    ,\n",
       "         1.    ,  0.    ,  0.    ],\n",
       "       [ 3.    , 26.    ,  0.    ,  0.    ,  7.925 ,  1.    ,  0.    ,\n",
       "         0.    ,  0.    ,  1.    ],\n",
       "       [ 1.    , 35.    ,  1.    ,  0.    , 53.1   ,  1.    ,  0.    ,\n",
       "         0.    ,  0.    ,  1.    ],\n",
       "       [ 3.    , 35.    ,  0.    ,  0.    ,  8.05  ,  0.    ,  1.    ,\n",
       "         0.    ,  0.    ,  1.    ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <div style=\"font-family: 'Garamond', serif; font-size: 22px; color: #ffffff; background-color: #34568B; text-align: center; padding: 15px; border-radius: 10px; border: 2px solid #FF6F61; box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">Step 3: Train the model</div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Splitting the data into training and validation sets</div>"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:08:33.558777Z",
     "start_time": "2025-09-05T03:08:33.545178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split data into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_valid shape: {y_valid.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (712, 7)\n",
      "X_valid shape: (179, 7)\n",
      "y_train shape: (712,)\n",
      "y_valid shape: (179,)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Training the XGBoost model</div>"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:10:00.710036Z",
     "start_time": "2025-09-05T03:10:00.634620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the XGBoost model\n",
    "xgb_model = XGBClassifier( eval_metric='logloss')\n",
    "\n",
    "# Create and evaluate the pipeline\n",
    "xgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('model', xgb_model)])\n",
    "\n",
    "# Preprocessing of training data, fit model\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get probability predictions\n",
    "valid_probs = xgb_pipeline.predict_proba(X_valid)\n",
    "\n",
    "# Extracting the probabilities for the 'Transported' class\n",
    "valid_transported_probs = valid_probs[:, 1]\n",
    "\n",
    "# Evaluate the model using AUC\n",
    "auc_score = roc_auc_score(y_valid, valid_transported_probs)\n",
    "auc_score"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709137709137709"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <div style=\"font-family: 'Garamond', serif; font-size: 22px; color: #ffffff; background-color: #34568B; text-align: center; padding: 15px; border-radius: 10px; border: 2px solid #FF6F61; box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">Step 4: Randomized Search Cross Validation</div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Hyperparameter Tuning with Randomized Search CV</div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sometimes, the default parameters of a model may not yield the best performance. To optimize the model's performance, we can use techniques like Randomized Search Cross-Validation to find the best hyperparameters."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:16:07.870032Z",
     "start_time": "2025-09-05T03:16:00.452366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'model__n_estimators': np.arange(50, 200, 10),\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'model__max_depth': np.arange(3, 10, 2),\n",
    "    'model__min_child_weight': np.arange(1, 6, 2)\n",
    "}\n",
    "\n",
    "# Create the randomized search with 10 fold cross-validation\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,  # Number of parameter settings that are sampled\n",
    "    scoring='roc_auc',\n",
    "    cv=10,  # 10-fold cross-validation\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the random search model\n",
    "xgb_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "best_params = xgb_random_search.best_params_\n",
    "best_score = xgb_random_search.best_score_\n",
    "\n",
    "best_params, best_score"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'model__n_estimators': np.int64(160),\n",
       "  'model__min_child_weight': np.int64(5),\n",
       "  'model__max_depth': np.int64(5),\n",
       "  'model__learning_rate': 0.01},\n",
       " np.float64(0.8576796454574233))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Evaluating the best hyperparameters performance</div>"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:16:12.913761Z",
     "start_time": "2025-09-05T03:16:12.853056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xgb_model_tuned = XGBClassifier(\n",
    "    n_estimators=best_params['model__n_estimators'],\n",
    "    learning_rate=best_params['model__learning_rate'],\n",
    "    max_depth=best_params['model__max_depth'],\n",
    "    min_child_weight=best_params['model__min_child_weight'],\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Update the pipeline\n",
    "xgb_pipeline.set_params(model=xgb_model)\n",
    "\n",
    "# Fit the model with the training data\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "valid_probs_tuned = xgb_pipeline.predict_proba(X_valid)\n",
    "\n",
    "# Extracting the probabilities for the 'Survived' class\n",
    "valid_survived_probs_tuned = valid_probs_tuned[:, 1]\n",
    "\n",
    "# Evaluate the tuned model using AUC\n",
    "auc_score_tuned = roc_auc_score(y_valid, valid_survived_probs_tuned)\n",
    "auc_score_tuned"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709137709137709"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Comparing AUC scores before and after tuning</div>"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:19:55.185573Z",
     "start_time": "2025-09-05T03:19:55.172361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the AUC scores before and after tuning\n",
    "print(f\"AUC Score before tuning: {auc_score:.4f}\")\n",
    "print(f\"AUC Score after tuning: {auc_score_tuned:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score before tuning: 0.8709\n",
      "AUC Score after tuning: 0.8709\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Determine the probability threshold for classification by accuracy.</div>"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:23:22.103042Z",
     "start_time": "2025-09-05T03:23:22.060508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Search for the best threshold\n",
    "best_threshold = 0.5\n",
    "best_accuracy = 0\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (valid_survived_probs_tuned >= threshold).astype(int)\n",
    "    accuracy = accuracy_score(y_valid, y_pred)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.2f} with Accuracy: {best_accuracy:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.77 with Accuracy: 0.8156\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <div style=\"font-family: 'Garamond', serif; font-size: 22px; color: #ffffff; background-color: #34568B; text-align: center; padding: 15px; border-radius: 10px; border: 2px solid #FF6F61; box-shadow: 0 6px 12px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">Step 5: Make predictions on the test set</div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Create the submission file and check the format</div>"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:26:00.022144Z",
     "start_time": "2025-09-05T03:25:59.998098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the test dataset\n",
    "test_data_path = os.path.join(extract_folder_path, 'test.csv')\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# Preprocessing of test data, make probability predictions\n",
    "test_probs = xgb_pipeline.predict_proba(test_data)\n",
    "\n",
    "# Extracting the probabilities for the 'Survived' class\n",
    "test_survived_probs = test_probs[:, 1]\n",
    "\n",
    "# Applying the best threshold to get binary predictions\n",
    "test_predictions = (test_survived_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Load the sample submission file to compare formats\n",
    "sample_submission_path = os.path.join(extract_folder_path, 'gender_submission.csv')\n",
    "sample_submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': test_predictions\n",
    "})\n",
    "\n",
    "# See if the submission format matches the sample submission\n",
    "print('Submission shape:', submission.shape)\n",
    "print('Sample submission shape:', sample_submission.shape)\n",
    "\n",
    "print('submission head:')\n",
    "print(submission.head())\n",
    "\n",
    "print('sample submission head:')\n",
    "print(sample_submission.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (418, 2)\n",
      "Sample submission shape: (418, 2)\n",
      "submission head:\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         0\n",
      "sample submission head:\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         1\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<div style=\"font-family: 'Lucida Sans Unicode', sans-serif; font-size: 18px; color: #4A235A; background-color: #D7BDE2; text-align: left; padding: 10px; border-left: 5px solid #7D3C98; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.2); margin-bottom: 10px;\">Save the submission file</div>"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T03:27:48.803389Z",
     "start_time": "2025-09-05T03:27:48.793306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the file path for the output CSV file\n",
    "output_csv_path = 'submission.csv'\n",
    "\n",
    "# Save the output DataFrame to a CSV file\n",
    "submission.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Return the path of the saved file\n",
    "output_csv_path"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submission.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
